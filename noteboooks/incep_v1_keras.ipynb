{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 19:01:39.520594: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-31 19:01:39.621067: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-31 19:01:39.649976: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-05-31 19:01:40.100300: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-31 19:01:40.100356: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-31 19:01:40.100361: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "import glob\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 19:01:41.011193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-31 19:01:41.033537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-31 19:01:41.033668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-31 19:01:41.034413: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-31 19:01:41.036787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-31 19:01:41.036913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-31 19:01:41.036992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-31 19:01:41.461807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-31 19:01:41.461964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-31 19:01:41.462053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-31 19:01:41.462134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20780 MB memory:  -> device: 0, name: NVIDIA A10, pci bus id: 0000:06:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "gpu_list = [0]\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "final_gpu_list = [\n",
    "    physical_devices[x] for x in range(len(physical_devices)) if x in gpu_list\n",
    "]\n",
    "tf.config.set_visible_devices(final_gpu_list, \"GPU\")\n",
    "logical_gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "# As data and model has to be copied on all of GPUs.\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "# To copy and get data from all places we use autotune.\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('../../files/train/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1 if x.split('/')[-1].split('.')[0] == 'dog' else 0 for x in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imgs(img, label, shape):\n",
    "    img = tf.io.read_file(img)\n",
    "    img = tf.image.decode_jpeg(img, channels = 3)\n",
    "    img = tf.image.resize(img, (shape, shape))\n",
    "    img = img / 255\n",
    "    label = tf.cast(label, dtype = tf.float32)\n",
    "    return img, label\n",
    "\n",
    "def get_data(data, shape=64, repeat = True, batch = True, batch_size = 32):\n",
    "    data, labels, shapes = [x[0] for x in data], [x[1] for x in data], [shape for x in range(len(data))]\n",
    "    tensor = tf.data.Dataset.from_tensor_slices((data, labels, shapes))\n",
    "    tensor = tensor.cache()\n",
    "    tensor = tensor.map(read_imgs, num_parallel_calls=AUTO)\n",
    "    if repeat:\n",
    "        tensor = tensor.repeat()\n",
    "    if batch:\n",
    "        tensor = tensor.batch(batch_size * REPLICAS)\n",
    "    tensor = tensor.prefetch(AUTO)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(files[x], labels[x]) for x in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_init = keras.initializers.Constant(value=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Incepv1_module](../images/incep_v1_module.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incep_module(x,\n",
    "                 filters_1x1,\n",
    "                 filters_3x3_reduce,\n",
    "                 filters_3x3,\n",
    "                 filters_5x5_reduce,\n",
    "                 filters_5x5,\n",
    "                 filters_pool_proj,\n",
    "                 name = None):\n",
    "    # Most left in above image single 1x1 convolution\n",
    "    conv_1x1 = layers.Conv2D(filters_1x1, (1, 1), padding = 'same', bias_initializer = bias_init)(x)\n",
    "    \n",
    "    # 1x1 and 3x3 conv from above image\n",
    "    conv_3x3 = layers.Conv2D(filters_3x3_reduce, (1, 1), padding = 'same', bias_initializer = bias_init)(x)\n",
    "    conv_3x3 = layers.Conv2D(filters_3x3, (3, 3), padding = 'same', bias_initializer = bias_init)(conv_3x3)\n",
    "\n",
    "    # 1x1 and 5x5conv from above image\n",
    "    conv_5x5 = layers.Conv2D(filters_5x5_reduce, (1, 1), padding = 'same', bias_initializer = bias_init)(x)\n",
    "    conv_5x5 = layers.Conv2D(filters_5x5, (5, 5), padding = 'same', bias_initializer = bias_init)(conv_5x5)\n",
    "\n",
    "    # 3x3 max pool and 1x1 conv\n",
    "    pool_proj = layers.MaxPool2D((3,3), (1,1), padding = 'same')(x)\n",
    "    pool_proj = layers.Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu', bias_initializer=bias_init)(pool_proj)\n",
    "\n",
    "    # return conv_1x1, conv_3x3, conv_5x5, pool_proj\n",
    "\n",
    "    output = tf.keras.layers.concatenate([\n",
    "        conv_1x1, conv_3x3, conv_5x5, pool_proj\n",
    "    ], axis = 3)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_incep_model(image_size):\n",
    "    input_layer = layers.Input((image_size[0], image_size[1], 3), name = 'input_layer')\n",
    "    c1 = layers.Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='c1/7x7/2', bias_initializer=bias_init)(input_layer)\n",
    "    max1 = layers.MaxPool2D((3, 3), padding='same', strides=(2, 2), name = 'maxpool_1')(c1)\n",
    "    c2 = layers.Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='c2/1x1/2')(max1)\n",
    "    c3 = layers.Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='c2/3x3/2')(c2)\n",
    "    max2 = layers.MaxPool2D((3, 3), padding='same', strides=(2, 2), name = 'maxpool_2')(c3)\n",
    "\n",
    "    # return max2\n",
    "    incep1 = incep_module(max2,\n",
    "                          filters_1x1=64,\n",
    "                          filters_3x3_reduce=96,\n",
    "                          filters_3x3=128,\n",
    "                          filters_5x5_reduce=16,\n",
    "                          filters_5x5=32,\n",
    "                          filters_pool_proj=32,\n",
    "                          name='inception_3a')\n",
    "    \n",
    "    incep2 = incep_module(incep1,\n",
    "                          filters_1x1=128,\n",
    "                          filters_3x3_reduce=128,\n",
    "                          filters_3x3=192,\n",
    "                          filters_5x5_reduce=32,\n",
    "                          filters_5x5=96,\n",
    "                          filters_pool_proj=64,\n",
    "                          name='inception_3b')\n",
    "    max3 = layers.MaxPool2D((3, 3), padding='same', strides=(2, 2), name = 'maxpool_3')(incep2)\n",
    "\n",
    "    incep3 = incep_module(max3,\n",
    "                          filters_1x1=192,\n",
    "                          filters_3x3_reduce=96,\n",
    "                          filters_3x3=208,\n",
    "                          filters_5x5_reduce=16,\n",
    "                          filters_5x5=48,\n",
    "                          filters_pool_proj=64,\n",
    "                          name='inception_4a')\n",
    "    \n",
    "    # we have to define auxillary outputs here\n",
    "    aux1 = layers.AveragePooling2D((5, 5), strides=3)(incep3)\n",
    "    aux1 = layers.Conv2D(128, (1, 1), padding = 'same', activation = 'relu')(aux1)\n",
    "    aux1 = layers.Flatten()(aux1)\n",
    "    aux1 = layers.Dense(1024, activation='relu')(aux1)\n",
    "    aux1 = layers.Dropout(0.7)(aux1)\n",
    "    aux1 = layers.Dense(1, activation='sigmoid', name='aux_output_1')(aux1)\n",
    "\n",
    "    incep4 = incep_module(incep3,\n",
    "                          filters_1x1=160,\n",
    "                          filters_3x3_reduce=112,\n",
    "                          filters_3x3=224,\n",
    "                          filters_5x5_reduce=24,\n",
    "                          filters_5x5=64,\n",
    "                          filters_pool_proj=64,\n",
    "                          name='inception_4b')\n",
    "    \n",
    "    incep5 = incep_module(incep4,\n",
    "                          filters_1x1=128,\n",
    "                          filters_3x3_reduce=128,\n",
    "                          filters_3x3=256,\n",
    "                          filters_5x5_reduce=24,\n",
    "                          filters_5x5=64,\n",
    "                          filters_pool_proj=64,\n",
    "                          name='inception_4c')\n",
    "    \n",
    "    incep6 = incep_module(incep5,\n",
    "                          filters_1x1=112,\n",
    "                          filters_3x3_reduce=144,\n",
    "                          filters_3x3=288,\n",
    "                          filters_5x5_reduce=32,\n",
    "                          filters_5x5=64,\n",
    "                          filters_pool_proj=64,\n",
    "                          name='inception_4d')\n",
    "    \n",
    "    # we have to define auxillary outputs here\n",
    "    aux2 = layers.AveragePooling2D((5, 5), 3)(incep6)\n",
    "    aux2 = layers.Conv2D(128, (1, 1), padding = 'same', activation = 'relu')(aux2)\n",
    "    aux2 = layers.Flatten()(aux2)\n",
    "    aux2 = layers.Dense(1024, activation='relu')(aux2)\n",
    "    aux2 = layers.Dropout(0.7)(aux2)\n",
    "    aux2 = layers.Dense(1, activation='sigmoid', name='aux_output_2')(aux2)\n",
    "    \n",
    "    incep7 = incep_module(incep6,\n",
    "                          filters_1x1=256,\n",
    "                          filters_3x3_reduce=160,\n",
    "                          filters_3x3=320,\n",
    "                          filters_5x5_reduce=32,\n",
    "                          filters_5x5=128,\n",
    "                          filters_pool_proj=128,\n",
    "                          name='inception_4e')\n",
    "\n",
    "    max4 = layers.MaxPool2D((3, 3), 2, padding='same', name = 'maxpool_4')(incep7)\n",
    "\n",
    "    incep8 = incep_module(max4,\n",
    "                          filters_1x1=256,\n",
    "                          filters_3x3_reduce=160,\n",
    "                          filters_3x3=320,\n",
    "                          filters_5x5_reduce=32,\n",
    "                          filters_5x5=128,\n",
    "                          filters_pool_proj=128,\n",
    "                          name='inception_5a')\n",
    "    \n",
    "    incep9 = incep_module(incep8,\n",
    "                          filters_1x1=384,\n",
    "                          filters_3x3_reduce=192,\n",
    "                          filters_3x3=384,\n",
    "                          filters_5x5_reduce=48,\n",
    "                          filters_5x5=128,\n",
    "                          filters_pool_proj=128,\n",
    "                          name='inception_5b')\n",
    "    \n",
    "    ap = layers.GlobalAveragePooling2D(name='global_avg_pooling')(incep9)\n",
    "    \n",
    "    d1 = layers.Dropout(0.4)(ap)\n",
    "\n",
    "    d2 = layers.Dense(1000, activation = 'relu')(d1)\n",
    "\n",
    "    d3 = layers.Dense(1, activation='sigmoid')(d2)\n",
    "\n",
    "    model = keras.Model(input_layer, [d3], name = 'incep_v1')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.metrics.Accuracy(thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_new_model(model):\n",
    "    with strategy.scope():\n",
    "        loss = keras.losses.BinaryCrossentropy()\n",
    "        optimizer = keras.optimizers.Adam()\n",
    "        metrics = [\n",
    "            keras.metrics.Accuracy()\n",
    "        ]\n",
    "        model.compile(\n",
    "            loss = loss,\n",
    "            optimizer = optimizer, \n",
    "            metrics = metrics\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = create_incep_model((256, 256))\n",
    "    model = compile_new_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"incep_v1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_layer (InputLayer)       [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " c1/7x7/2 (Conv2D)              (None, 128, 128, 64  9472        ['input_layer[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " maxpool_1 (MaxPooling2D)       (None, 64, 64, 64)   0           ['c1/7x7/2[0][0]']               \n",
      "                                                                                                  \n",
      " c2/1x1/2 (Conv2D)              (None, 64, 64, 64)   4160        ['maxpool_1[0][0]']              \n",
      "                                                                                                  \n",
      " c2/3x3/2 (Conv2D)              (None, 64, 64, 192)  110784      ['c2/1x1/2[0][0]']               \n",
      "                                                                                                  \n",
      " maxpool_2 (MaxPooling2D)       (None, 32, 32, 192)  0           ['c2/3x3/2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_505 (Conv2D)            (None, 32, 32, 96)   18528       ['maxpool_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_507 (Conv2D)            (None, 32, 32, 16)   3088        ['maxpool_2[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_81 (MaxPooling2D  (None, 32, 32, 192)  0          ['maxpool_2[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_504 (Conv2D)            (None, 32, 32, 64)   12352       ['maxpool_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_506 (Conv2D)            (None, 32, 32, 128)  110720      ['conv2d_505[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_508 (Conv2D)            (None, 32, 32, 32)   12832       ['conv2d_507[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_509 (Conv2D)            (None, 32, 32, 32)   6176        ['max_pooling2d_81[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_81 (Concatenate)   (None, 32, 32, 256)  0           ['conv2d_504[0][0]',             \n",
      "                                                                  'conv2d_506[0][0]',             \n",
      "                                                                  'conv2d_508[0][0]',             \n",
      "                                                                  'conv2d_509[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_511 (Conv2D)            (None, 32, 32, 128)  32896       ['concatenate_81[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_513 (Conv2D)            (None, 32, 32, 32)   8224        ['concatenate_81[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling2d_82 (MaxPooling2D  (None, 32, 32, 256)  0          ['concatenate_81[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_510 (Conv2D)            (None, 32, 32, 128)  32896       ['concatenate_81[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_512 (Conv2D)            (None, 32, 32, 192)  221376      ['conv2d_511[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_514 (Conv2D)            (None, 32, 32, 96)   76896       ['conv2d_513[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_515 (Conv2D)            (None, 32, 32, 64)   16448       ['max_pooling2d_82[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_82 (Concatenate)   (None, 32, 32, 480)  0           ['conv2d_510[0][0]',             \n",
      "                                                                  'conv2d_512[0][0]',             \n",
      "                                                                  'conv2d_514[0][0]',             \n",
      "                                                                  'conv2d_515[0][0]']             \n",
      "                                                                                                  \n",
      " maxpool_3 (MaxPooling2D)       (None, 16, 16, 480)  0           ['concatenate_82[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_517 (Conv2D)            (None, 16, 16, 96)   46176       ['maxpool_3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_519 (Conv2D)            (None, 16, 16, 16)   7696        ['maxpool_3[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_83 (MaxPooling2D  (None, 16, 16, 480)  0          ['maxpool_3[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_516 (Conv2D)            (None, 16, 16, 192)  92352       ['maxpool_3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_518 (Conv2D)            (None, 16, 16, 208)  179920      ['conv2d_517[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_520 (Conv2D)            (None, 16, 16, 48)   19248       ['conv2d_519[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_521 (Conv2D)            (None, 16, 16, 64)   30784       ['max_pooling2d_83[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_83 (Concatenate)   (None, 16, 16, 512)  0           ['conv2d_516[0][0]',             \n",
      "                                                                  'conv2d_518[0][0]',             \n",
      "                                                                  'conv2d_520[0][0]',             \n",
      "                                                                  'conv2d_521[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_524 (Conv2D)            (None, 16, 16, 112)  57456       ['concatenate_83[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_526 (Conv2D)            (None, 16, 16, 24)   12312       ['concatenate_83[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling2d_84 (MaxPooling2D  (None, 16, 16, 512)  0          ['concatenate_83[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_523 (Conv2D)            (None, 16, 16, 160)  82080       ['concatenate_83[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_525 (Conv2D)            (None, 16, 16, 224)  226016      ['conv2d_524[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_527 (Conv2D)            (None, 16, 16, 64)   38464       ['conv2d_526[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_528 (Conv2D)            (None, 16, 16, 64)   32832       ['max_pooling2d_84[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_84 (Concatenate)   (None, 16, 16, 512)  0           ['conv2d_523[0][0]',             \n",
      "                                                                  'conv2d_525[0][0]',             \n",
      "                                                                  'conv2d_527[0][0]',             \n",
      "                                                                  'conv2d_528[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_530 (Conv2D)            (None, 16, 16, 128)  65664       ['concatenate_84[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_532 (Conv2D)            (None, 16, 16, 24)   12312       ['concatenate_84[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling2d_85 (MaxPooling2D  (None, 16, 16, 512)  0          ['concatenate_84[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_529 (Conv2D)            (None, 16, 16, 128)  65664       ['concatenate_84[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_531 (Conv2D)            (None, 16, 16, 256)  295168      ['conv2d_530[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_533 (Conv2D)            (None, 16, 16, 64)   38464       ['conv2d_532[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_534 (Conv2D)            (None, 16, 16, 64)   32832       ['max_pooling2d_85[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_85 (Concatenate)   (None, 16, 16, 512)  0           ['conv2d_529[0][0]',             \n",
      "                                                                  'conv2d_531[0][0]',             \n",
      "                                                                  'conv2d_533[0][0]',             \n",
      "                                                                  'conv2d_534[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_536 (Conv2D)            (None, 16, 16, 144)  73872       ['concatenate_85[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_538 (Conv2D)            (None, 16, 16, 32)   16416       ['concatenate_85[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling2d_86 (MaxPooling2D  (None, 16, 16, 512)  0          ['concatenate_85[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_535 (Conv2D)            (None, 16, 16, 112)  57456       ['concatenate_85[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_537 (Conv2D)            (None, 16, 16, 288)  373536      ['conv2d_536[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_539 (Conv2D)            (None, 16, 16, 64)   51264       ['conv2d_538[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_540 (Conv2D)            (None, 16, 16, 64)   32832       ['max_pooling2d_86[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_86 (Concatenate)   (None, 16, 16, 528)  0           ['conv2d_535[0][0]',             \n",
      "                                                                  'conv2d_537[0][0]',             \n",
      "                                                                  'conv2d_539[0][0]',             \n",
      "                                                                  'conv2d_540[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_543 (Conv2D)            (None, 16, 16, 160)  84640       ['concatenate_86[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_545 (Conv2D)            (None, 16, 16, 32)   16928       ['concatenate_86[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling2d_87 (MaxPooling2D  (None, 16, 16, 528)  0          ['concatenate_86[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_542 (Conv2D)            (None, 16, 16, 256)  135424      ['concatenate_86[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_544 (Conv2D)            (None, 16, 16, 320)  461120      ['conv2d_543[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_546 (Conv2D)            (None, 16, 16, 128)  102528      ['conv2d_545[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_547 (Conv2D)            (None, 16, 16, 128)  67712       ['max_pooling2d_87[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_87 (Concatenate)   (None, 16, 16, 832)  0           ['conv2d_542[0][0]',             \n",
      "                                                                  'conv2d_544[0][0]',             \n",
      "                                                                  'conv2d_546[0][0]',             \n",
      "                                                                  'conv2d_547[0][0]']             \n",
      "                                                                                                  \n",
      " maxpool_4 (MaxPooling2D)       (None, 8, 8, 832)    0           ['concatenate_87[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_549 (Conv2D)            (None, 8, 8, 160)    133280      ['maxpool_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_551 (Conv2D)            (None, 8, 8, 32)     26656       ['maxpool_4[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_88 (MaxPooling2D  (None, 8, 8, 832)   0           ['maxpool_4[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_548 (Conv2D)            (None, 8, 8, 256)    213248      ['maxpool_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_550 (Conv2D)            (None, 8, 8, 320)    461120      ['conv2d_549[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_552 (Conv2D)            (None, 8, 8, 128)    102528      ['conv2d_551[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_553 (Conv2D)            (None, 8, 8, 128)    106624      ['max_pooling2d_88[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_88 (Concatenate)   (None, 8, 8, 832)    0           ['conv2d_548[0][0]',             \n",
      "                                                                  'conv2d_550[0][0]',             \n",
      "                                                                  'conv2d_552[0][0]',             \n",
      "                                                                  'conv2d_553[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_555 (Conv2D)            (None, 8, 8, 192)    159936      ['concatenate_88[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_557 (Conv2D)            (None, 8, 8, 48)     39984       ['concatenate_88[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling2d_89 (MaxPooling2D  (None, 8, 8, 832)   0           ['concatenate_88[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_554 (Conv2D)            (None, 8, 8, 384)    319872      ['concatenate_88[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_556 (Conv2D)            (None, 8, 8, 384)    663936      ['conv2d_555[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_558 (Conv2D)            (None, 8, 8, 128)    153728      ['conv2d_557[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_559 (Conv2D)            (None, 8, 8, 128)    106624      ['max_pooling2d_89[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_89 (Concatenate)   (None, 8, 8, 1024)   0           ['conv2d_554[0][0]',             \n",
      "                                                                  'conv2d_556[0][0]',             \n",
      "                                                                  'conv2d_558[0][0]',             \n",
      "                                                                  'conv2d_559[0][0]']             \n",
      "                                                                                                  \n",
      " global_avg_pooling (GlobalAver  (None, 1024)        0           ['concatenate_89[0][0]']         \n",
      " agePooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, 1024)         0           ['global_avg_pooling[0][0]']     \n",
      "                                                                                                  \n",
      " dense_33 (Dense)               (None, 1000)         1025000     ['dropout_29[0][0]']             \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 1)            1001        ['dense_33[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,999,553\n",
      "Trainable params: 6,999,553\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = get_data(data, shape=256, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 19:47:22.096168: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "input: \"Placeholder/_2\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 25000\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\026TensorSliceDataset:289\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 40s 47ms/step - loss: 0.7160 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6966 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6859 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6757 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6623 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6533 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6376 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6151 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.5789 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.5223 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4e41fcdc0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_,\n",
    "          steps_per_epoch=len(data) // (32 * REPLICAS),\n",
    "          epochs = 10,\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = get_data(data, shape=256, batch_size=32, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 19:53:32.836090: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "input: \"Placeholder/_2\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 25000\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\026TensorSliceDataset:307\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 13s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(data_, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.906713  ],\n",
       "       [0.20937087],\n",
       "       [0.7852278 ],\n",
       "       ...,\n",
       "       [0.6930758 ],\n",
       "       [0.5030427 ],\n",
       "       [0.44181105]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 19:54:15.456710: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "input: \"Placeholder/_2\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 25000\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\026TensorSliceDataset:330\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 41s 47ms/step - loss: 254.2637 - accuracy: 0.0331\n",
      "Epoch 2/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.7092 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6930 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6895 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6848 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6742 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "781/781 [==============================] - 37s 48ms/step - loss: 0.6590 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6567 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6548 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "781/781 [==============================] - 37s 47ms/step - loss: 0.6483 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4e4380ee0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Adam optimizer\n",
    "model.fit(data_,\n",
    "          steps_per_epoch=len(data) // (32 * REPLICAS),\n",
    "          epochs = 10,\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
