{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "gpu_list = [0]\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "final_gpu_list = [\n",
    "    physical_devices[x] for x in range(len(physical_devices)) if x in gpu_list\n",
    "]\n",
    "tf.config.set_visible_devices(final_gpu_list, \"GPU\")\n",
    "logical_gpus = tf.config.list_logical_devices(\"GPU\")\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "# As data and model has to be copied on all of GPUs.\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "# To copy and get data from all places we use autotune.\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vgg_16(image_size, filters):\n",
    "    input = layers.Input((image_size, image_size, 3))\n",
    "    c1 = layers.Conv2D(filters = filters, \n",
    "                       kernel_size = 3, \n",
    "                       padding = 'same', \n",
    "                       activation = 'relu')(input)\n",
    "    c2 = layers.Conv2D(filters = filters, \n",
    "                       kernel_size = 3, \n",
    "                       padding = 'same', \n",
    "                       activation = 'relu')(c1)\n",
    "    p1 = layers.MaxPool2D(2, 2)(c2)\n",
    "    c3 = layers.Conv2D(filters = filters * 2, \n",
    "                       kernel_size = 3, \n",
    "                       padding = 'same', \n",
    "                       activation = 'relu')(p1)\n",
    "    c4 = layers.Conv2D(filters = filters * 2, \n",
    "                       kernel_size = 3, \n",
    "                       padding = 'same', \n",
    "                       activation = 'relu')(c3)\n",
    "    p2 = layers.MaxPool2D(2, 2)(c4)\n",
    "    filters = filters * 2\n",
    "    c5 = layers.Conv2D(filters = filters * 2, \n",
    "                       kernel_size = 3, \n",
    "                       padding = 'same', \n",
    "                       activation = 'relu')(p2)\n",
    "    c6 = layers.Conv2D(filters = filters * 2, \n",
    "                       kernel_size = 3, \n",
    "                       padding = 'same', \n",
    "                       activation = 'relu')(c5)\n",
    "    c7 = layers.Conv2D(filters = filters * 2, \n",
    "                       kernel_size = 3, \n",
    "                       padding = 'same', \n",
    "                       activation = 'relu')(c6)\n",
    "    p3 = layers.MaxPool2D(2, 2)(c7)\n",
    "    filters *= 2\n",
    "    c8 = layers.Conv2D(filters = filters * 2, \n",
    "                       kernel_size = 3, \n",
    "                       padding = 'same', \n",
    "                       activation = 'relu')(p3)\n",
    "    c9 = layers.Conv2D(filters = filters * 2, \n",
    "                       kernel_size = 3, \n",
    "                       padding = 'same', \n",
    "                       activation = 'relu')(c8)\n",
    "    c10 = layers.Conv2D(filters = filters * 2, \n",
    "                       kernel_size = 3, \n",
    "                       padding = 'same', \n",
    "                       activation = 'relu')(c9)\n",
    "    p4 = layers.MaxPool2D(2, 2)(c10)\n",
    "    c11 = layers.Conv2D(filters = filters * 2, \n",
    "                       kernel_size = 3, \n",
    "                       padding = 'same', \n",
    "                       activation = 'relu')(p4)\n",
    "    c12 = layers.Conv2D(filters = filters * 2, \n",
    "                       kernel_size = 3, \n",
    "                       padding = 'same', \n",
    "                       activation = 'relu')(c11)\n",
    "    c13 = layers.Conv2D(filters = filters * 2, \n",
    "                       kernel_size = 3, \n",
    "                       padding = 'same', \n",
    "                       activation = 'relu')(c12)\n",
    "    p5 = layers.MaxPool2D(2, 2)(c13)\n",
    "    f1 = layers.Flatten()(p5)\n",
    "    d1 = layers.Dense(4096, activation = 'relu')(f1)\n",
    "    d2 = layers.Dense(4096, activation = 'relu')(d1)\n",
    "    d3 = layers.Dense(1, activation = 'sigmoid')(d2)\n",
    "    model = Model(inputs=[input], outputs = [d3])\n",
    "    return model\n",
    "\n",
    "def compile_model(model):\n",
    "    optim = keras.optimizers.SGD()\n",
    "    loss = keras.losses.BinaryCrossentropy()\n",
    "    metrics = [\n",
    "        keras.metrics.Precision(),\n",
    "        keras.metrics.Recall()\n",
    "    ]\n",
    "    model.compile(\n",
    "        optimizer = optim,\n",
    "        loss = loss,\n",
    "        metrics = metrics\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_vgg_16(64, 64)\n",
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('../../files/train/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1 if x.split('/')[-1].split('.')[0] == 'dog' else 0 for x in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imgs(img, label, shape):\n",
    "    img = tf.io.read_file(img)\n",
    "    img = tf.image.decode_jpeg(img, channels = 3)\n",
    "    img = tf.image.resize(img, (shape, shape))\n",
    "    return img, label\n",
    "\n",
    "def get_data(data, shape=64, repeat = True, batch = True, batch_size = 32):\n",
    "    data, labels, shapes = [x[0] for x in data], [x[1] for x in data], [shape for x in range(len(data))]\n",
    "    tensor = tf.data.Dataset.from_tensor_slices((data, labels, shapes))\n",
    "    tensor = tensor.cache()\n",
    "    tensor = tensor.map(read_imgs, num_parallel_calls=AUTO)\n",
    "    if repeat:\n",
    "        tensor = tensor.repeat()\n",
    "    if batch:\n",
    "        tensor = tensor.batch(batch_size * REPLICAS)\n",
    "    tensor = tensor.prefetch(AUTO)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(files[x], labels[x]) for x in range(len(files))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 184s 222ms/step - loss: 0.6703 - precision_3: 0.5872 - recall_3: 0.6291\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data(data, 256)\n",
    "batch_size = 32\n",
    "model = create_vgg_16(256, 64)\n",
    "model = compile_model(model)\n",
    "model_hist = model.fit(\n",
    "    train_data,\n",
    "    epochs = 1,\n",
    "    verbose = 1,\n",
    "    steps_per_epoch = len(files) // (REPLICAS * batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pre_trained(image_size):\n",
    "    with strategy.scope():\n",
    "        input = layers.Input((image_size, image_size, 3))\n",
    "        model = keras.applications.VGG16(include_top=False, weights=None, input_shape=(image_size, image_size, 3), pooling='max')(input)\n",
    "        output_layer = layers.Dense(1, 'sigmoid')(model)\n",
    "        model = Model(input, output_layer)\n",
    "\n",
    "        optim = keras.optimizers.SGD()\n",
    "        loss = keras.losses.BinaryCrossentropy()\n",
    "        metrics = [\n",
    "            keras.metrics.Precision(),\n",
    "            keras.metrics.Recall()\n",
    "        ]\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer = optim,\n",
    "            loss = loss,\n",
    "            metrics = metrics\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 18:51:55.861784: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_3\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "input: \"Placeholder/_1\"\n",
      "input: \"Placeholder/_2\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "      type: DT_INT32\n",
      "      type: DT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: 25000\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"is_files\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\025TensorSliceDataset:24\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"replicate_on_split\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_STRING\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 169s 213ms/step - loss: 0.6621 - precision_10: 0.5969 - recall_10: 0.6007\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data(data, 256)\n",
    "batch_size = 32\n",
    "pre_model = create_pre_trained(256)\n",
    "model_hist = pre_model.fit(\n",
    "    train_data,\n",
    "    epochs = 1,\n",
    "    verbose = 1,\n",
    "    steps_per_epoch = len(files) // (REPLICAS * batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7fa8e84e3610>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "tensor_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
